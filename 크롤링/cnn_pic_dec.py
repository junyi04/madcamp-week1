import os
import json
import torch
import torch.nn as nn
import torchvision.models as models
import torchvision.transforms as transforms
from PIL import Image
import numpy as np
import shutil
import cv2
from pathlib import Path
from tqdm import tqdm
from datetime import datetime
from ultralytics import YOLO
from facenet_pytorch import MTCNN, InceptionResnetV1
from sklearn.metrics.pairwise import cosine_similarity

# ===========================
# ğŸ›ï¸ RTX 4060 í™˜ê²½ ìµœì í™” ì„¤ì •
# ===========================
SIMILARITY_THRESHOLD = 0.85 
W_COSINE = 0.7              # ResNet 3-Pass (ê¸°ì¡´ ê¸°ëŠ¥) ê°€ì¤‘ì¹˜
W_FACE = 0.3                # ì–¼êµ´ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜
TARGET_DATE_FOLDER = datetime.now().strftime("%Y-%m-%d") 
BATCH_SIZE = 16             # 4060 VRAM(8GB) ê³ ë ¤
QUARANTINE_FOLDER = "duplicates_storage" 
QUARANTINE_JSON_LOG = os.path.join(QUARANTINE_FOLDER, "quarantined_json_data.json")

# ğŸ“ [ê²½ë¡œ ì—ëŸ¬ í•´ê²°] ëª¨ë¸ ì €ì¥ ê²½ë¡œë¥¼ C ë“œë¼ì´ë¸Œ í”„ë¡œì íŠ¸ í´ë”ë¡œ ê°•ì œ ì§€ì •
project_root = Path.cwd()
model_cache_dir = project_root / "models_cache"
model_cache_dir.mkdir(parents=True, exist_ok=True)
os.environ['TORCH_HOME'] = str(model_cache_dir) # í™˜ê²½ë³€ìˆ˜ ì„¤ì •
torch.hub.set_dir(str(model_cache_dir))        # Hub ê²½ë¡œ ì„¤ì •
# ===========================

device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# 1. ëª¨ë¸ ë¡œë“œ (ê¸°ì¡´ ResNet 3-Pass ê¸°ëŠ¥ í¬í•¨)
# weights_only=False ì„¤ì •ì„ í†µí•´ ê°€ì¤‘ì¹˜ ë¡œë“œ ì—ëŸ¬ ë°©ì§€
resnet50 = models.resnet50(weights=models.ResNet50_Weights.DEFAULT)
resnet50 = nn.Sequential(*list(resnet50.children())[:-1]).to(device).eval()

yolo = YOLO('yolov8n.pt') 
mtcnn = MTCNN(keep_all=False, device=device) 
facenet = InceptionResnetV1(pretrained='vggface2').to(device).eval()

# ğŸ¨ [ê¸°ëŠ¥ ìœ ì§€] 3-Pass ì „ì²˜ë¦¬ (Center, Full, Zoom)
preprocess = {
    "center": transforms.Compose([transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]),
    "full": transforms.Compose([transforms.Resize((224, 224)), transforms.ToTensor(), transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])]),
    "zoom": transforms.Compose([transforms.Resize(400), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize([0.485,0.456,0.406],[0.229,0.224,0.225])])
}

def get_face_embedding(img_p):
    try:
        img = Image.open(img_p).convert('RGB')
        face = mtcnn(img)
        if face is not None:
            return facenet(face.unsqueeze(0).to(device)).detach().cpu().numpy(), True
    except: pass
    return None, False

def move_and_visualize(src_path, dest_path, item):
    """YOLO ë°•ìŠ¤ ì‹œê°í™” í›„ ê²©ë¦¬ ì´ë™"""
    os.makedirs(QUARANTINE_FOLDER, exist_ok=True)
    results = yolo(src_path, verbose=False)
    img = cv2.imread(str(src_path))
    for r in results:
        for box in r.boxes:
            if box.cls == 0: # person íƒì§€ ì‹œ
                b = box.xyxy[0].cpu().numpy().astype(int)
                cv2.rectangle(img, (b[0], b[1]), (b[2], b[3]), (0, 255, 0), 3)
                cv2.putText(img, "AI DUPLICATE", (b[0], b[1]-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0, 255, 0), 2)
    cv2.imwrite(str(dest_path), img)
    if os.path.exists(src_path): os.remove(src_path)
    with open(QUARANTINE_JSON_LOG, "a", encoding="utf-8") as f:
        f.write(json.dumps(item, ensure_ascii=False) + "\n")

if __name__ == "__main__":
    print(f"ğŸš€ [RTX 4060] AI ì •ë°€ ì •ì œ ì‹œì‘ | ëŒ€ìƒ: {TARGET_DATE_FOLDER}")
    
    # ì´ë¯¸ì§€ ìˆ˜ì§‘
    all_paths = [str(p) for p in Path(TARGET_DATE_FOLDER).glob("**/thumbnails/*.jpg")]
    if len(all_paths) < 2: 
        print("âœ… ë¶„ì„í•  ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤."); exit()

    valid_paths, res_feats, face_feats = [], [], {}
    for p in tqdm(all_paths, desc="ğŸ§  3-Pass ë¶„ì„ ì¤‘"):
        try:
            img = Image.open(p).convert('RGB')
            # â­ [ê¸°ëŠ¥ ìœ ì§€] ResNet 3-Pass TTA
            with torch.no_grad():
                f_avg = (resnet50(preprocess["center"](img).unsqueeze(0).to(device)) +
                         resnet50(preprocess["full"](img).unsqueeze(0).to(device)) +
                         resnet50(preprocess["zoom"](img).unsqueeze(0).to(device))) / 3.0
                res_feats.append(torch.flatten(f_avg, 1).cpu().numpy())
            
            emb, ok = get_face_embedding(p)
            if ok: face_feats[p] = emb
            valid_paths.append(p)
        except: continue

    res_feats = np.vstack(res_feats)
    res_sim = cosine_similarity(res_feats)

    deleted_indices = set()
    deleted_info_by_cat = {}

    for i in range(len(valid_paths)):
        if i in deleted_indices: continue
        for j in range(i + 1, len(valid_paths)):
            if j in deleted_indices: continue
            
            s_res = res_sim[i][j]
            pi, pj = valid_paths[i], valid_paths[j]
            
            # â­ [ê°€ì¤‘ì¹˜ 7:3 ë°˜ì˜]
            if pi in face_feats and pj in face_feats:
                s_face = cosine_similarity(face_feats[pi], face_feats[pj])[0][0]
                final_score = (s_res * W_COSINE) + (s_face * W_FACE)
            else:
                final_score = s_res

            if final_score >= SIMILARITY_THRESHOLD:
                deleted_indices.add(j)
                p_path = Path(pj)
                cat = p_path.parent.parent.name
                if cat not in deleted_info_by_cat: deleted_info_by_cat[cat] = []
                deleted_info_by_cat[cat].append(p_path.stem)

    print(f"ğŸ“¦ {len(deleted_indices)}ê°œ ì¤‘ë³µ ê²©ë¦¬ ë° JSON ë™ê¸°í™” ì§„í–‰")
    for idx in sorted(list(deleted_indices), reverse=True):
        p_path = valid_paths[idx]
        dest = Path(QUARANTINE_FOLDER) / f"DUP_{Path(p_path).name}"
        category = Path(p_path).parent.parent.name
        move_and_visualize(p_path, dest, {"cat": category, "id": Path(p_path).stem})

    # JSON ì—…ë°ì´íŠ¸ ë° ì œëª© ì—†ìŒ ë³´ì •
    for cat, d_ids in deleted_info_by_cat.items():
        j_path = Path(TARGET_DATE_FOLDER) / cat / f"{cat}_data.json"
        if j_path.exists():
            with open(j_path, "r", encoding="utf-8") as f:
                data_list = json.load(f)
            
            new_list = []
            for item in data_list:
                if item.get("id") not in d_ids:
                    if not item.get('title') or item['title'].strip() == "":
                        item['title'] = "ì œëª© ì—†ìŒ"
                    new_list.append(item)
            
            with open(j_path, "w", encoding="utf-8") as f:
                json.dump(new_list, f, ensure_ascii=False, indent=2)

    print("ğŸ‰ ì •ì œ ì‘ì—… ì™„ë£Œ.")