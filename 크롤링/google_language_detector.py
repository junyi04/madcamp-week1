import os
import json
import shutil
import re
from pathlib import Path
from google.cloud import translate_v2 as translate
from tqdm import tqdm
from datetime import datetime

# ===========================
# ğŸ›ï¸ ì„¤ì • ì˜ì—­
# ===========================
os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = "google_key.json"
TARGET_DATE_FOLDER = datetime.now().strftime("%Y-%m-%d") 
QUARANTINE_FOLDER = "non_korean_quarantine"

translate_client = translate.Client()
# ===========================

def is_korean_ai(text):
    """êµ¬ê¸€ APIë¥¼ ì‚¬ìš©í•˜ë˜, ì§§ì€ í…ìŠ¤íŠ¸ ë° í•œê¸€ í¬í•¨ ì—¬ë¶€ë¥¼ ìš°ì„  ìˆœìœ„ë¡œ ë‘¡ë‹ˆë‹¤."""
    if not text or text.strip() == "":
        return False
    
    # 1. í•œê¸€ì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ ë¨¼ì € ì²´í¬ (ì •ê·œì‹)
    korean_chars = re.sub('[^ê°€-í£]', '', text)
    if len(korean_chars) > 0:
        # í•œê¸€ì´ 2ê¸€ì ì´ìƒ í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ ì¼ë‹¨ í•œêµ­ì–´ë¡œ ê°„ì£¼ (API ë¹„ìš© ì ˆê° ë° ìœ ì‹¤ ë°©ì§€)
        if len(korean_chars) >= 2:
            return True
            
        # í•œê¸€ì´ 1ê¸€ìë§Œ ìˆëŠ” ê²½ìš° APIë¡œ ì •ë°€ ê²€ì‚¬
        try:
            result = translate_client.detect_language(text)
            if result['language'] == 'ko':
                return True
        except:
            return False
    
    return False

if __name__ == "__main__":
    print(f"ğŸš€ [NLP ì´ì¤‘ ê²€ì¦] í•„í„°ë§ ì‹œì‘ | ëŒ€ìƒ: {TARGET_DATE_FOLDER}")
    
    base_path = Path(TARGET_DATE_FOLDER)
    # _data.json íŒŒì¼ë“¤ë§Œ íƒìƒ‰ (top10 í´ë” ì œì™¸)
    json_files = [p for p in base_path.glob("**/*_data.json") if "top10" not in str(p)]
    
    for json_path in json_files:
        cat_name = json_path.parent.name
        filtered_data = []
        removed_count = 0
        
        try:
            with open(json_path, "r", encoding="utf-8") as f:
                # â­ [í•µì‹¬ ìˆ˜ì •] í‘œì¤€ JSON ë°°ì—´ í˜•ì‹ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ì½ê¸°
                all_data = json.load(f)
        except Exception as e:
            print(f"âš ï¸ {json_path} ì½ê¸° ì‹¤íŒ¨: {e}")
            continue

        for data in tqdm(all_data, desc=f"ğŸŒ [{cat_name.upper()}] ë¶„ì„ ì¤‘"):
            title = data.get("title", "").strip()
            author = data.get("author", "").strip()
            img_file = data.get("image_file")

            # â­ [ë¡œì§ ìˆ˜ì •] ì œëª© í˜¹ì€ ì‘ì„±ì ì¤‘ í•˜ë‚˜ë¼ë„ í•œêµ­ì–´ë¼ë©´ ìœ ì§€
            # ì œëª©ì— í•œê¸€ì´ ì—†ì–´ë„ ì‘ì„±ìê°€ í•œêµ­ì¸ì´ë©´ í•œêµ­ ë¦´ìŠ¤ì¼ í™•ë¥ ì´ ë§¤ìš° ë†’ìŒ
            is_korean = is_korean_ai(title) or is_korean_ai(author)

            if is_korean:
                filtered_data.append(data)
            else:
                # ê²©ë¦¬ì†Œ ì´ë™ ë¡œì§
                os.makedirs(QUARANTINE_FOLDER, exist_ok=True)
                img_p = Path(img_file)
                # ì‹¤ì œ ì´ë¯¸ì§€ ê²½ë¡œê°€ category í´ë” ì•ˆì— ìˆëŠ”ì§€ í™•ì¸
                real_img_path = json_path.parent / img_p.name if not img_p.exists() else img_p
                
                if real_img_path.exists():
                    dest_path = os.path.join(QUARANTINE_FOLDER, f"nonko_{cat_name}_{real_img_path.name}")
                    shutil.move(str(real_img_path), dest_path)
                
                removed_count += 1

        # â­ [í•µì‹¬ ìˆ˜ì •] í•„í„°ë§ëœ ê²°ê³¼ë¬¼ë„ ë‹¤ì‹œ í‘œì¤€ ë°°ì—´ í˜•ì‹ìœ¼ë¡œ ì €ì¥
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(filtered_data, f, ensure_ascii=False, indent=2)
        
        print(f"   âœ… {cat_name}: {removed_count}ê°œ ì œì™¸ ì™„ë£Œ")

    print(f"ğŸ‰ ëª¨ë“  í•„í„°ë§ì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")