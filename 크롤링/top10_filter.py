import os
import json
import shutil
from pathlib import Path
from datetime import datetime

# ===========================
# ğŸ›ï¸ ì„¤ì • ì˜ì—­
# ===========================
TARGET_DATE_FOLDER = datetime.now().strftime("%Y-%m-%d") 
TOP_LIMIT = 10
ARCHIVE_ROOT = Path("residual_archive")
RETENTION_DAYS = 3
STATUS_FILE = "crawl_status.json"
LOG_FILE = "execution_log.txt"
# ===========================

def update_status(status="success"):
    """crawl_status.json ì—…ë°ì´íŠ¸"""
    data = {}
    if os.path.exists(STATUS_FILE):
        with open(STATUS_FILE, "r", encoding="utf-8") as f:
            try: data = json.load(f)
            except: data = {}
    data[TARGET_DATE_FOLDER] = status
    with open(STATUS_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, indent=2, ensure_ascii=False)

def write_execution_log(message):
    """execution_log.txtì— ì‹¤í–‰ ì‹œê°„ ê¸°ë¡"""
    now = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
    with open(LOG_FILE, "a", encoding="utf-8") as log:
        log.write(f"[{now}] {message}\n")

def safe_move(src, dst):
    """í´ë”/íŒŒì¼ ì´ë™ ì‹œ ì´ë¯¸ ì¡´ì¬í•˜ë©´ ì‚­ì œ í›„ ì´ë™ (shutil.Error ë°©ì§€)"""
    src, dst = Path(src), Path(dst)
    if not src.exists(): return
    if dst.exists():
        if dst.is_dir(): shutil.rmtree(dst)
        else: os.remove(dst)
    dst.parent.mkdir(parents=True, exist_ok=True)
    shutil.move(str(src), str(dst))

def clean_old_archive():
    if not ARCHIVE_ROOT.exists(): return
    today = datetime.now()
    for folder in ARCHIVE_ROOT.iterdir():
        if folder.is_dir():
            try:
                folder_date = datetime.strptime(folder.name, "%Y-%m-%d")
                if (today - folder_date).days >= RETENTION_DAYS:
                    shutil.rmtree(folder)
            except: continue

def process_top10_with_main_merge():
    base_path = Path(TARGET_DATE_FOLDER)
    if not base_path.exists():
        print(f"âŒ í´ë” ì—†ìŒ: {TARGET_DATE_FOLDER}")
        return

    # --- Step 1: Main í´ë”ë¡œ ëª¨ë“  ë°ì´í„° ë¬¼ë¦¬ì  ë³µì‚¬ ë° ë³‘í•© ---
    main_dir = base_path / "main"
    main_thumb_dir = main_dir / "thumbnails"
    main_thumb_dir.mkdir(parents=True, exist_ok=True)
    
    main_total_list = []
    other_categories = [d for d in base_path.iterdir() if d.is_dir() and d.name != "main"]

    print(f"ğŸ“¦ [Step 1] ëª¨ë“  ë°ì´í„°ë¥¼ Mainìœ¼ë¡œ í†µí•© ì¤‘...")
    for cat_dir in other_categories:
        json_path = cat_dir / f"{cat_dir.name}_data.json"
        if not json_path.exists(): continue

        with open(json_path, "r", encoding="utf-8") as f:
            try:
                cat_data = json.load(f)
                for item in cat_data:
                    # ì¸ë„¤ì¼ ê²½ë¡œ í™•ì¸ ë° ë³µì‚¬
                    old_img = Path(item['image_file'])
                    if not old_img.exists():
                        old_img = cat_dir / "thumbnails" / old_img.name
                    
                    new_img_path = main_thumb_dir / old_img.name
                    if old_img.exists() and not new_img_path.exists():
                        shutil.copy(old_img, new_img_path)
                    
                    # ì œëª© ì—†ìŒ ë³´ì • (Hole ë°˜ì˜)
                    if not item.get('title') or str(item['title']).strip() == "":
                        item['title'] = "ì œëª© ì—†ìŒ"
                    
                    item['image_file'] = str(new_img_path).replace("\\", "/")
                    main_total_list.append(item)
            except: continue

    # main_data.json ì €ì¥ (ì „ì²´ ë°ì´í„° í•©ë³¸)
    main_json_path = main_dir / "main_data.json"
    with open(main_json_path, "w", encoding="utf-8") as f:
        json.dump(main_total_list, f, ensure_ascii=False, indent=2)

    # --- Step 2: ëª¨ë“  í´ë”(Main í¬í•¨)ì—ì„œ TOP 10 ì¶”ì¶œ ì‘ì—… ìˆ˜í–‰ ---
    print(f"ğŸš€ [Step 2] ì¹´í…Œê³ ë¦¬ë³„ TOP 10 ì¶”ì¶œ ì‹œì‘...")
    all_target_dirs = [d for d in base_path.iterdir() if d.is_dir()]
    
    for target_dir in all_target_dirs:
        cat_name = target_dir.name
        raw_json = target_dir / f"{cat_name}_data.json"
        if not raw_json.exists(): continue
        run_ranking_logic(target_dir, raw_json, cat_name)

    # --- Step 3: ì •í™”, ë³´ê´€ ë° ë¡œê·¸ ê¸°ë¡ ---
    finalize_and_archive(base_path)
    write_execution_log("í†µí•© ë©”ì¸ í¬í•¨ ëª¨ë“  ì¹´í…Œê³ ë¦¬ ì •ì œ ë° ì•„ì¹´ì´ë¸Œ ì™„ë£Œ")
    print(f"\nâœ¨ ì‘ì—… ì™„ë£Œ! execution_log.txt ë° crawl_status.json ì—…ë°ì´íŠ¸ë¨.")

def run_ranking_logic(target_dir, json_path, cat_name):
    with open(json_path, "r", encoding="utf-8") as f:
        data_list = json.load(f)
    
    # URL ì¤‘ë³µ ì œê±°
    unique_map = {}
    for item in data_list:
        url = item.get("url")
        if url:
            if url not in unique_map or item.get('views', 0) > unique_map[url].get('views', 0):
                unique_map[url] = item

    # TOP 10 ì •ë ¬
    top10_list = sorted(unique_map.values(), key=lambda x: x.get('views', 0), reverse=True)[:TOP_LIMIT]

    top10_dir = target_dir / "top10"
    top10_thumb_dir = top10_dir / "thumbnails"
    top10_thumb_dir.mkdir(parents=True, exist_ok=True)

    final_results = []
    for i, video in enumerate(top10_list, start=1):
        new_id = f"{cat_name}{str(i).zfill(2)}"
        old_img = Path(video['image_file'])
        new_img = top10_thumb_dir / f"{new_id}.jpg"
        
        if old_img.exists():
            shutil.copy(old_img, new_img)
        
        # ì œëª© ì—†ìŒ ë³´ì • (ì¤‘ì²© ë°©ì–´)
        if not video.get('title') or str(video['title']).strip() == "":
            video['title'] = "ì œëª© ì—†ìŒ"
            
        video['id'] = new_id
        video['image_file'] = f"/static/{TARGET_DATE_FOLDER}/{cat_name}/top10/thumbnails/{new_id}.jpg"
        final_results.append(video)

    with open(top10_dir / f"{cat_name}_top10.json", "w", encoding="utf-8") as f:
        json.dump(final_results, f, ensure_ascii=False, indent=2)
    print(f" Â  âœ… {cat_name} ì™„ë£Œ")

def finalize_and_archive(base_path):
    archive_date_path = ARCHIVE_ROOT / TARGET_DATE_FOLDER
    archive_date_path.mkdir(parents=True, exist_ok=True)
    
    for cat_dir in [d for d in base_path.iterdir() if d.is_dir() and d.name != "top10"]:
        archive_cat = archive_date_path / cat_dir.name
        
        # ì›ë³¸ thumbnails ì´ë™ (safe_move ì ìš©)
        src_thumb = cat_dir / "thumbnails"
        dst_thumb = archive_cat / "thumbnails"
        if src_thumb.exists():
            safe_move(src_thumb, dst_thumb)
            
        # ì›ë³¸ raw json ì´ë™ (safe_move ì ìš©)
        raw_json = cat_dir / f"{cat_dir.name}_data.json"
        dst_json = archive_cat / f"{cat_dir.name}_raw.json"
        if raw_json.exists():
            safe_move(raw_json, dst_json)

    clean_old_archive()
    update_status("success")

if __name__ == "__main__":
    process_top10_with_main_merge()